{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS #\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, MaxPool2D, BatchNormalization, Concatenate\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS #\n",
    "\n",
    "IMAGE_X = 300\n",
    "IMAGE_Y = 300\n",
    "\n",
    "GAUSSIAN_X = 48\n",
    "GAUSSIAN_Y = 48\n",
    "\n",
    "SCALE_FACTOR = 8\n",
    "\n",
    "LABEL_X = IMAGE_X // SCALE_FACTOR\n",
    "LABEL_Y = IMAGE_Y // SCALE_FACTOR\n",
    "\n",
    "# Range for Random Gen\n",
    "MIN_NUM_GAUSSIANS = 2\n",
    "MAX_NUM_GAUSSIANS = 5\n",
    "\n",
    "MIN_STD_X = 7\n",
    "MAX_STD_X = 12\n",
    "\n",
    "MIN_STD_Y = 7\n",
    "MAX_STD_Y = 12\n",
    "\n",
    "MIN_THETA = 0\n",
    "MAX_THETA = np.pi\n",
    "\n",
    "MIN_INTENSITY = 0.05\n",
    "MAX_INTENSITY = 0.7\n",
    "\n",
    "THRESHOLD = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Gaussian Functions\n",
    "def img_gen(VERBOSE: bool = False) -> tuple:\n",
    "\n",
    "    img = np.zeros(shape=(IMAGE_Y, IMAGE_X, 1))\n",
    "    label = np.zeros(shape=(LABEL_Y, LABEL_X, 1))\n",
    "    params = []\n",
    "\n",
    "    num_gaussians = np.random.randint(low=MIN_NUM_GAUSSIANS, high=MAX_NUM_GAUSSIANS)\n",
    "    for gaussian in range(num_gaussians):\n",
    "\n",
    "        # Randomize params\n",
    "        center_x = np.random.randint(low=0 + GAUSSIAN_X // 2, high=IMAGE_X - GAUSSIAN_X // 2)\n",
    "        center_y = np.random.randint(low=0 + GAUSSIAN_Y // 2, high=IMAGE_Y - GAUSSIAN_Y // 2)\n",
    "\n",
    "        std_x = np.random.randint(low=MIN_STD_X, high=MAX_STD_X)\n",
    "        std_y = np.random.randint(low=MIN_STD_Y, high=MAX_STD_Y)\n",
    "        theta = np.random.randint(low=MIN_THETA, high=MAX_THETA)\n",
    "        \n",
    "        intensity = np.random.uniform(low=MIN_INTENSITY, high=MAX_INTENSITY)\n",
    "        \n",
    "        # Generate Gaussian\n",
    "        params.append((center_x, center_y, std_x, std_y, theta, intensity))\n",
    "        gaussian = gaussian_gen(center_x, center_y, std_x, std_y, theta)\n",
    "\n",
    "        # Add Gaussian to img\n",
    "        img += intensity * gaussian\n",
    "        \n",
    "        label_x = center_x // SCALE_FACTOR\n",
    "        label_y = center_y // SCALE_FACTOR\n",
    "\n",
    "        label[label_y, label_x] = 1\n",
    "\n",
    "    # Convert to 8 bit int\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "\n",
    "    # DEBUG\n",
    "    if VERBOSE:\n",
    "        # print(f\"[Image Shape]: {str(img.shape)}\")\n",
    "        # print(f\"[Label Shape]: {str(label.shape)}\")\n",
    "        print(f\"[Target Gaussians #]: {str(num_gaussians)}\")\n",
    "        for param in params:\n",
    "            print(\n",
    "            f\"[(c_x, c_y)]: ({param[0]:<3}, {param[1]:<3}) \"\n",
    "            f\"[(s_x, s_y)]: ({param[2]:<3}, {param[3]:<3}) \"\n",
    "            f\"[Theta]: {param[4]:.2f} \"\n",
    "            f\"[I]: {param[5]:.2f} \"\n",
    "            )\n",
    "\n",
    "    return (img, label, params)\n",
    "\n",
    "def gaussian_gen(center_x: int, center_y: int, std_x: int, std_y: int, theta: float) -> np.ndarray:\n",
    "    X = np.arange(0, IMAGE_X, 1)\n",
    "    Y = np.arange(0, IMAGE_Y, 1)\n",
    "    X, Y = np.meshgrid(X, Y)\n",
    "\n",
    "    cos_theta_sqrd = np.pow(np.cos(theta),2)\n",
    "    sin_theta_sqrd = np.pow(np.sin(theta),2)\n",
    "    sin_cos_theta = np.sin(theta) * np.cos(theta)\n",
    "\n",
    "    std_x_sqrd = np.pow(std_x, 2)\n",
    "    std_y_sqrd = np.pow(std_y, 2)\n",
    "\n",
    "    a = (cos_theta_sqrd) / (2 * std_x_sqrd) + (sin_theta_sqrd) / (2 * std_y_sqrd)\n",
    "    b = -1 * (sin_cos_theta) / (2 * std_x_sqrd) + (sin_cos_theta) / (2 * std_y_sqrd)\n",
    "    c = (sin_theta_sqrd) / (2 * std_x_sqrd) + (cos_theta_sqrd) / (2 * std_y_sqrd)\n",
    "\n",
    "    gaussian = np.exp(-(a * (X - center_x)**2 + 2*b * (X - center_x) * (Y - center_y) + c * (Y - center_y)**2))\n",
    "\n",
    "    return np.expand_dims(gaussian, -1)\n",
    "\n",
    "def img_shift():\n",
    "    pass\n",
    "\n",
    "def img_scale():\n",
    "    pass\n",
    "\n",
    "def img_visualization_one(img: np.ndarray, label: np.ndarray, params: list, threshold: int = THRESHOLD) -> None:\n",
    "    rgb_image = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Coords of Gaussians:\n",
    "    for x in range(LABEL_X):\n",
    "        for y in range(LABEL_Y):\n",
    "            if label[y, x,] == 1:\n",
    "                \n",
    "                top_left = (x * SCALE_FACTOR - GAUSSIAN_X // 2, y * SCALE_FACTOR - GAUSSIAN_Y // 2)\n",
    "                bottom_right = (x * SCALE_FACTOR + GAUSSIAN_X // 2, y * SCALE_FACTOR + GAUSSIAN_Y // 2)\n",
    "                color = (0, 200, 200)\n",
    "                thickness = 2\n",
    "                \n",
    "                cv2.rectangle(rgb_image, top_left, bottom_right, color, thickness)\n",
    "\n",
    "    for param in params:\n",
    "        print(\n",
    "        f\"[(c_x, c_y)]: ({param[0]:<3}, {param[1]:<3}) \"\n",
    "        f\"[(s_x, s_y)]: ({param[2]:<3}, {param[3]:<3}) \"\n",
    "        f\"[Theta]: {param[4]:.2f} \"\n",
    "        f\"[I]: {param[5]:.2f} \"\n",
    "        )\n",
    "    \n",
    "    plt.imshow(rgb_image)\n",
    "\n",
    "\n",
    "\n",
    "def img_visualization_two(img: np.ndarray, label: np.ndarray, params: list) -> None:\n",
    "    \n",
    "    for param in params:\n",
    "        print(\n",
    "        f\"[(c_x, c_y)]: ({param[0]:<3}, {param[1]:<3}) \"\n",
    "        f\"[(s_x, s_y)]: ({param[2]:<3}, {param[3]:<3}) \"\n",
    "        f\"[Theta]: {param[4]:.2f} \"\n",
    "        f\"[I]: {param[5]:.2f} \"\n",
    "        )\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(label, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Functions: \n",
    "img, label, params = img_gen()\n",
    "img_visualization_one(img, label, params)\n",
    "# img_visualization_two(img, label, params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Training Data\n",
    "SAMPLE_COUNT = 10000\n",
    "img_arr = []\n",
    "label_arr = []\n",
    "\n",
    "def process_image():\n",
    "    img, label, _ = img_gen()\n",
    "    return img, label\n",
    "\n",
    "img_arr = []\n",
    "label_arr = []\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = [executor.submit(process_image) for _ in range(SAMPLE_COUNT)]\n",
    "    for future in tqdm(as_completed(futures), total=SAMPLE_COUNT):\n",
    "        img, label = future.result()\n",
    "        # img_arr.append(img / (np.max(img) + 1)) # Normalize values to [0, 1)\n",
    "        img_arr.append(img)\n",
    "        label_arr.append(label)\n",
    "\n",
    "img_arr = np.array(img_arr).astype(np.float32)\n",
    "label_arr = np.array(label_arr).astype(np.float32)\n",
    "\n",
    "print(f'[Images Shape]: {img_arr.shape}')\n",
    "print(f'[Labels Shape]: {label_arr.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Data to tf DataSet \n",
    "BATCH_SIZE = 32\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((img_arr, label_arr))\n",
    "dataset = dataset.shuffle(SAMPLE_COUNT, reshuffle_each_iteration=True)\n",
    "dataset = dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture (INCREASE FILTER SIZE? 16, 32, 64)\n",
    "input_layer = Input(shape=(IMAGE_X, IMAGE_Y, 1), name='InputLayer')\n",
    "\n",
    "x = Conv2D(filters=16, kernel_size=3, strides=1, padding='same', kernel_initializer='lecun_uniform')(input_layer)\n",
    "x = BatchNormalization(axis=-1, momentum=0.1, epsilon=1e-05)(x)\n",
    "x = ReLU()(x)\n",
    "x = MaxPool2D(pool_size=2)(x)\n",
    "\n",
    "x = Conv2D(filters=16, kernel_size=3, strides=1, padding='same', kernel_initializer='lecun_uniform')(x)\n",
    "x = BatchNormalization(axis=-1, momentum=0.1, epsilon=1e-05)(x)\n",
    "x = ReLU()(x)\n",
    "x = MaxPool2D(pool_size=2)(x)\n",
    "\n",
    "x = Conv2D(filters=16, kernel_size=3, strides=1, padding='same', kernel_initializer='lecun_uniform')(x)\n",
    "x = BatchNormalization(axis=-1, momentum=0.1, epsilon=1e-05)(x)\n",
    "x = ReLU()(x)\n",
    "x = MaxPool2D(pool_size=2)(x)\n",
    "\n",
    "x_prob = Conv2D(1, kernel_size=3, padding='same', name='x_prob', activation='sigmoid', kernel_initializer='lecun_uniform')(x)\n",
    "\n",
    "baby_yolo = Model(inputs=input_layer, outputs=x_prob, name='baby_yolo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow Functions\n",
    "@tf.function\n",
    "def loss_p(y_true, y_pred):\n",
    "    loss = tf.losses.binary_crossentropy(y_true, y_pred)\n",
    "    return tf.reduce_sum(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "\n",
    "num_epochs = 200\n",
    "\n",
    "# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#     initial_learning_rate=0.01,\n",
    "#     decay_steps=num_epochs,\n",
    "#     decay_rate=0.9)\n",
    "\n",
    "lr_schedule = 0.001\n",
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "baby_yolo.compile(optimizer=adam_optimizer, loss=loss_p, run_eagerly=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch in tqdm(dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            prediction = baby_yolo(batch[0])\n",
    "            loss = loss_p(batch[1], prediction)\n",
    "        grads = tape.gradient(loss, baby_yolo.trainable_variables)\n",
    "        adam_optimizer.apply_gradients(zip(grads, baby_yolo.trainable_variables))\n",
    "        running_loss += loss.numpy()\n",
    "        \n",
    "    average_loss = running_loss / len(dataset)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hls4ml-Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
